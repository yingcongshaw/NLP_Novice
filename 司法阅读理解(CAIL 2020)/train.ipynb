{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chinese-bert-wwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python baseline/run_cail.py \\\n",
    "    --name 'chinese-bert-wwm' \\\n",
    "    --bert_model '../../../Download/chinese-bert-wwm' \\\n",
    "    --data_dir './output/data/chinese-bert-wwm' \\\n",
    "    --batch_size 2 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --lr 1e-5 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --seed 56 \\\n",
    "    --epochs 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chinese-roberta-wwm-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python baseline/run_cail.py \\\n",
    "    --name 'chinese-roberta-wwm-ext' \\\n",
    "    --bert_model '../../../Download/chinese-roberta-wwm-ext' \\\n",
    "    --data_dir './output/data/chinese-roberta-wwm-ext' \\\n",
    "    --batch_size 2 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --lr 1e-5 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --seed 56 \\\n",
    "    --epochs 25 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chinese-roberta-wwm-ext-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python baseline/run_cail.py \\\n",
    "    --name 'chinese-roberta-wwm-ext-large' \\\n",
    "    --bert_model '../../../Download/chinese-roberta-wwm-ext-large' \\\n",
    "    --data_dir './output/data/chinese-roberta-wwm-ext-large' \\\n",
    "    --batch_size 2 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --lr 1e-5 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --seed 56 \\\n",
    "    --epochs 25 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清华民事文书BERT：thunlp-ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python baseline/run_cail.py \\\n",
    "    --name 'thunlp-ms' \\\n",
    "    --bert_model '../../../Download/thunlp-ms' \\\n",
    "    --data_dir './output/data/thunlp-ms' \\\n",
    "    --batch_size 2 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --lr 1e-5 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --seed 56 \\\n",
    "    --epochs 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chinese-roberta-wwm-ext-large + 2019 训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python baseline/run_cail.py \\\n",
    "    --name 'chinese-roberta-wwm-ext-large_add19' \\\n",
    "    --bert_model '../../../Download/chinese-roberta-wwm-ext-large' \\\n",
    "    --data_dir './output/data/chinese-roberta-wwm-ext-large_add19' \\\n",
    "    --batch_size 2 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --lr 1e-5 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --seed 56 \\\n",
    "    --epochs 25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
